{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2 (часть 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Морфология"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Предварительная подготовка\n",
    "Подключим исправления."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я взяла произведение Гончарова \"Фрегат\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"C:\\\\Users\\\\Андрей\\\\Downloads\\\\Гончаров. Фрегат.txt\"\n",
    "text = open(file, encoding=\"utf-8\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1)Обработка книги с помощью mystem:\n",
    "Нам нужно распарсить файл в формате txt с помощью mystem. Для этого применим метод analyze и замерим время работы для этой строчки. Затем разбор приведем к формату json и запишем в файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "# подключаем mystem\n",
    "from pymystem3 import Mystem\n",
    "m = Mystem(mystem_bin=\"C:\\\\Users\\\\Андрей\\\\Downloads\\\\mystem.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24min 46s\n"
     ]
    }
   ],
   "source": [
    "%time ana = m.analyze(text)\n",
    "if os.path.exists(\".\\\\mystem_anas.json\"):\n",
    "    mode = \"w\"\n",
    "else:\n",
    "    mode = \"x\"\n",
    "with open(\".\\\\mystem_anas.json\", mode, encoding=\"utf-8\") as f:\n",
    "    json_anas = json.dump(ana, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2)Обработка книги с помощью pymorphy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизируем текст, разбираем c помощью pymorphy и записывания произведенных разборов список и словарь(для скорости)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = []\n",
    "known_words = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:2: E228 missing whitespace around modulo operator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.9 ms ± 7.18 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for token in tokens:\n",
    "    if token in known_words:\n",
    "        lemmas.append(known_words[token])\n",
    "    else:\n",
    "        ana = morph.parse(token)\n",
    "        lemmas.append(ana)\n",
    "        known_words[token] = ana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из списка с разборами из каждого первого разбора получим слово, лемму и часть речи и запишем эти 3 значения в мини-словари слов, которые в свою очередь, поместим в общий список. В итоге получится список из словарей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# список, который мы потом переведем в json\n",
    "list_of_lemmas = []\n",
    "for lem in lemmas:\n",
    "    first = lem[0]\n",
    "    word_box = {}\n",
    "    word_box[\"word\"] = first.word\n",
    "    word_box[\"lemma\"] = first.normal_form\n",
    "    word_box[\"POS\"] = first.tag.POS\n",
    "    list_of_lemmas.append(word_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем список в файл в формате json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\".\\\\pymorphy_anas.json\"):\n",
    "    mode = \"w\"\n",
    "else:\n",
    "    mode = \"x\"\n",
    "with open(\".\\\\pymorphy_anas.json\", mode, encoding=\"utf-8\") as f:\n",
    "    json_anas = json.dump(list_of_lemmas, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Вопросы по словам\n",
    "###### 3.1 Доля слов для каждой части речи. \n",
    "Для этого воспользуемся списком, полученным благодяря pymorphy. Составим список из частей речи и преобразуем его в counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# список частей речи\n",
    "pos_list = []\n",
    "for item in list_of_lemmas:\n",
    "    if item[\"POS\"] is not None:\n",
    "        pos_list.append(item[\"POS\"])\n",
    "words_num = len(pos_list)\n",
    "pos_count = Counter(pos_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распечатаем получившийся каунтер (при этом поделив кол-во слов данной части речи на общее кол-во слов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Часть речи                    Доля в тексте\n",
      "NOUN                          0.27681510832495515\n",
      "PREP                          0.11840834269718296\n",
      "NUMR                          0.007609359906952905\n",
      "ADJF                          0.1174325309992706\n",
      "INTJ                          0.0030161452480927317\n",
      "ADVB                          0.06908549687543122\n",
      "PRTF                          0.009028722376643601\n",
      "PRCL                          0.04631655725747629\n",
      "VERB                          0.12183846866560215\n",
      "INFN                          0.022039545015474993\n",
      "NPRO                          0.06712401679578922\n",
      "GRND                          0.008220474303625288\n",
      "CONJ                          0.10827567173300215\n",
      "PRED                          0.005470459518599562\n",
      "ADJS                          0.010595935103593747\n",
      "PRTS                          0.004465077769235318\n",
      "COMP                          0.004258087409072092\n"
     ]
    }
   ],
   "source": [
    "print(\"{:<30}{}\".format(\"Часть речи\", \"Доля в тексте\"))\n",
    "for key, value in pos_count.items():\n",
    "    print(\"{:<30}{}\".format(key, value/words_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3.2 Топ-20 (по частотности) глаголов и наречий\n",
    "Опять же воспользуемся списком pymorphy. Сделаем список из глаголов и из наречий и преобразуем их в counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_list = []\n",
    "adverb_list = []\n",
    "for item in list_of_lemmas:\n",
    "    if item[\"POS\"] == \"VERB\":\n",
    "        verb_list.append(item[\"lemma\"].lower())\n",
    "    elif item[\"POS\"] == \"ADVB\":\n",
    "        adverb_list.append(item[\"lemma\"].lower())\n",
    "verb_count = Counter(verb_list)\n",
    "adverb_count = Counter(adverb_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распечатываем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-20 глаголов:\n",
      "Глагол                        Доля в тексте\n",
      "быть                          0.00923571273680683\n",
      "сказать                       0.002582451160131685\n",
      "мочь                          0.0017939164547479645\n",
      "спросить                      0.00166577956512311\n",
      "говорить                      0.0014982159402290693\n",
      "видеть                        0.0014883592564117728\n",
      "идти                          0.0013306523153350286\n",
      "стать                         0.0011335186389890984\n",
      "отвечать                      0.001103948587537209\n",
      "смотреть                      0.0010349518008161333\n",
      "знать                         0.0010349518008161333\n",
      "хотеть                        0.0009758116979123544\n",
      "сидеть                        0.0008476748082874997\n",
      "пойти                         0.0006899678672107556\n",
      "думать                        0.000640684448124273\n",
      "послать                       0.000640684448124273\n",
      "выйти                         0.00062097108048968\n",
      "ходить                        0.0005914010290377905\n",
      "жить                          0.0005716876614031975\n",
      "заметить                      0.0005519742937686045\n",
      "\n",
      "\n",
      "Топ-20 наречий:\n",
      "Наречие                       Доля в тексте\n",
      "здесь                         0.0019910501310938947\n",
      "там                           0.0019713367634593016\n",
      "где                           0.001744633035661482\n",
      "тут                           0.001744633035661482\n",
      "потом                         0.0017150629842095926\n",
      "опять                         0.0014883592564117728\n",
      "уже                           0.0013897924182388077\n",
      "вдруг                         0.0013109389477004357\n",
      "несколько                     0.001143375322806395\n",
      "почти                         0.0010546651684507264\n",
      "теперь                        0.0009856683817296508\n",
      "много                         0.0009659550140950578\n",
      "наконец                       0.0009166715950085753\n",
      "тоже                          0.0008871015435566858\n",
      "очень                         0.0008673881759220927\n",
      "особенно                      0.0007885347053837207\n",
      "уж                            0.0007589646539318312\n",
      "потому                        0.0007491079701145347\n",
      "более                         0.0007293946024799417\n",
      "всего                         0.0007293946024799417\n"
     ]
    }
   ],
   "source": [
    "# глаголы\n",
    "print(\"Топ-20 глаголов:\")\n",
    "print(\"{:<30}{}\".format(\"Глагол\", \"Доля в тексте\"))\n",
    "for verb, value in verb_count.most_common(20):\n",
    "    print(\"{:<30}{}\".format(verb, value/words_num))\n",
    "# наречия\n",
    "print(\"\\n\")\n",
    "print(\"Топ-20 наречий:\")\n",
    "print(\"{:<30}{}\".format(\"Наречие\", \"Доля в тексте\"))\n",
    "for adverb, value in adverb_count.most_common(20):\n",
    "    print(\"{:<30}{}\".format(adverb, value/words_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) N-Gramms\n",
    "Возьмем наши токены, которые мы уже делали ранее, приведем к нижнему регистру, оставим лишь слова. Затем составим список из биграмм и сделаем из них counter. То же самое проделаем с триграммами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# биграммы\n",
    "word_tokens = [w.lower() for w in tokens if w.isalpha()]\n",
    "biwords = [b for b in nltk.bigrams(word_tokens)]\n",
    "bigram_count = Counter(biwords)\n",
    "# триграммы\n",
    "triwords = [t for t in nltk.trigrams(word_tokens)]\n",
    "trigram_count = Counter(triwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-25 биграмм:\n",
      "Биграмма                      Кол-во в тексте\n",
      "и не                          114\n",
      "как будто                     102\n",
      "и в                           89\n",
      "то есть                       89\n",
      "у нас                         70\n",
      "что это                       70\n",
      "спросил я                     68\n",
      "не было                       68\n",
      "и на                          64\n",
      "у него                        61\n",
      "и с                           59\n",
      "я не                          59\n",
      "может быть                    58\n",
      "все это                       55\n",
      "потому что                    55\n",
      "между тем                     53\n",
      "сказал он                     52\n",
      "и все                         47\n",
      "и мы                          46\n",
      "что он                        44\n",
      "так что                       44\n",
      "отвечал он                    43\n",
      "сказал я                      42\n",
      "и я                           42\n",
      "в самом                       41\n",
      "\n",
      "\n",
      "Топ-25 триграмм:\n",
      "Триграмма                     Кол-во в тексте\n",
      "в самом деле                  37\n",
      "до сих пор                    30\n",
      "на другой день                22\n",
      "как у нас                     17\n",
      "а между тем                   16\n",
      "в одном месте                 15\n",
      "в первый раз                  13\n",
      "взад и вперед                 13\n",
      "мыса доброй надежды           13\n",
      "что это такое                 12\n",
      "в том числе                   12\n",
      "по крайней мере               11\n",
      "и между прочим                11\n",
      "мы с бароном                  11\n",
      "мы вошли в                    10\n",
      "у нас в                       10\n",
      "мысе доброй надежды           9\n",
      "что это за                    9\n",
      "что они не                    9\n",
      "том числе и                   9\n",
      "что у него                    9\n",
      "мыс доброй надежды            9\n",
      "на мысе доброй                8\n",
      "на то что                     8\n",
      "нужды нет что                 8\n"
     ]
    }
   ],
   "source": [
    "# биграммы\n",
    "print(\"Топ-25 биграмм:\")\n",
    "print(\"{:<30}{}\".format(\"Биграмма\", \"Кол-во в тексте\"))\n",
    "for bi, value in bigram_count.most_common(25):\n",
    "    lex_bi = bi[0] + \" \" + bi[1]\n",
    "    print(\"{:<30}{}\".format(lex_bi, value))\n",
    "print(\"\\n\")\n",
    "# триграммы\n",
    "print(\"Топ-25 триграмм:\")\n",
    "print(\"{:<30}{}\".format(\"Триграмма\", \"Кол-во в тексте\"))\n",
    "for tri, value in trigram_count.most_common(25):\n",
    "    lex_tri = tri[0] + \" \" + tri[1] + \" \" + tri[2]\n",
    "    print(\"{:<30}{}\".format(lex_tri, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
